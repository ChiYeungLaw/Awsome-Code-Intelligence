# Code Intelligence

üíª Welcome to the world of Code Intelligence!

Code Intelligence is an exciting field focused on automating code completion and generation. The ultimate objective is to develop intelligent models capable of generating code based on specific requirements. This repository serves as a comprehensive collection of the latest research and advancements in this domain.

## Foundation Models for Code

- Phi-1: Textbooks Are All You Need ([paper](https://arxiv.org/abs/2306.11644), 2023,  *close-source* ‚ùå)
- **WizardCoder**: Empowering Code Large Language Models with Evol-Instruct ([github](https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder), [paper](https://arxiv.org/abs/2306.08568), 2023, *open-source* ‚≠ï) 
- CodeT5+: Open Code Large Language Models for Code Understanding and Generation ([github](https://github.com/salesforce/CodeT5), [paper](https://arxiv.org/abs/2305.07922), 2023, *open-source* ‚≠ï)
- **StarCoder**: May the source be with you! ([github](https://github.com/bigcode-project/starcoder), [paper](https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view), 2023, *open-source* ‚≠ï)
- CodeGen2: Lessons for Training LLMs on Programming and Natural Languages ([github](https://github.com/salesforce/CodeGen2), [paper](https://arxiv.org/abs/2305.02309), 2023, *open-source* ‚≠ï)
- Replit-code-v1-3b ([github](https://github.com/replit/ReplitLM/tree/main/replit-code-v1-3b), [twitter](https://twitter.com/Replit/status/1651344184593506304), 2023, *open-source* ‚≠ï)
- GPT4 ([paper](https://arxiv.org/abs/2303.08774), 2023, *close-source* ‚ùå)
- SantaCoder: don't reach for the stars! ([github](https://huggingface.co/bigcode/santacoder), [paper](https://arxiv.org/abs/2301.03988), 2022, *open-source* ‚≠ï)
- CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X ([github](https://github.com/THUDM/CodeGeeX#codegeex-a-multilingual-code-generation-model), [paper](https://arxiv.org/abs/2303.17568), 2022, *open-source* ‚≠ï)
- CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis ([github](https://github.com/salesforce/CodeGen), [paper](https://arxiv.org/pdf/2203.13474.pdf), 2022, *open-source* ‚≠ï)
- Codex: Evaluating Large Language Models Trained on Code (2021, *close-source* ‚ùå)

## Leaderboard on HumanEval for Open-Source Models

| Model            | HumanEval Pass@1 |
|------------------|------------------|
| CodeGen-16B-Multi| 18.3             |
| CodeGeeX         | 22.9             |
| LLaMA-33B        | 21.7             |
| LLaMA-65B        | 23.7             |
| CodeGen-16B-Mono | 29.3             |
| Code-Cushman-001 | 33.5             |
| StarCoder-15B    | 33.6             |
| InstructCodeT5+  | 35.0             |
| WizardLM-30B  1.0| 37.8             |
| WizardCoder-15B  1.0 | **57.3**     |


## Training Methods for Code LLMs

## Prompt Engineering for Code LLMs

## Benchmarks
